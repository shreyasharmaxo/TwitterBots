{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.util import *\n",
    "\n",
    "from nltk.corpus import opinion_lexicon\n",
    "\n",
    "from nltk.corpus import TwitterCorpusReader\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tweets: list of strings ; lemmatizer: nltk Lemmatizer ; stemmer : nltk Stemmer\n",
    "#remove stopword and tokenize strings. lemmatize/stemming if lemmatizer/stemmer not None\n",
    "def preprocessString(tweets, lemmatizer, stemmer):\n",
    "    \n",
    "    #stopword\n",
    "    tweets = [w for w in tweets if w.lower() not in stopwords.words('english')]\n",
    "    #tokenize\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tweets = [tokenizer.tokenize(tweet) for tweet in tweets]\n",
    "    #lower\n",
    "    for i in range(len(tweets)):\n",
    "        tweets[i] = [t.lower() for t in tweets[i]]\n",
    "    \n",
    "    if lemmatizer != None:\n",
    "        for i in range(len(tweets)):\n",
    "            #lemmatization \n",
    "            tweets[i] = [lemmatizer.lemmatize(t) for t in tweets[i]]\n",
    "    if stemmer != None:\n",
    "        for i in range(len(tweets)):\n",
    "            #stemming \n",
    "            tweets[i] = [stemmer.stem(t) for t in tweets[i]]\n",
    "    \n",
    "    #Collocations, Bigrams, Trigrams\n",
    "    #Chunking\n",
    "            \n",
    "    return tweets\n",
    "\n",
    "#tweets: list of objects, tag: tag in string \n",
    "def add_tags(tweets, tag):\n",
    "    return [[tweet, tag] for tweet in tweets]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tweet data source (please follow https://www.nltk.org/data.html to download data)\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "#load\n",
    "neg_tweet = twitter_samples.strings(fileids = 'negative_tweets.json')\n",
    "pos_tweet = twitter_samples.strings(fileids = 'positive_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "#stemming\n",
    "pstemmer = nltk.PorterStemmer()\n",
    "\n",
    "#process tweets\n",
    "neg_tweetPro = preprocessString(neg_tweet, wnl, pstemmer)\n",
    "pos_tweetPro = preprocessString(pos_tweet, wnl, pstemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add tag\n",
    "neg_tweetTag = add_tags(neg_tweetPro, 0)\n",
    "pos_tweetTag = add_tags(pos_tweetPro, 1)\n",
    "docs = neg_tweetTag + pos_tweetTag\n",
    "random.shuffle(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split\n",
    "numTrainTweets = int(len(docs)*0.9)\n",
    "train_docs = docs[:numTrainTweets]\n",
    "test_docs = docs[numTrainTweets:]\n",
    "train_data = [data[0] for data in train_docs]\n",
    "train_label = [data[1] for data in train_docs]\n",
    "test_data = [data[0] for data in test_docs]\n",
    "test_label = [data[1] for data in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer\n",
    "def identity(x):\n",
    "    return x\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(preprocessor=identity, tokenizer=identity)\n",
    "trainX = vectorizer.fit_transform(train_data)\n",
    "\n",
    "#feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save vectorizer?\n",
    "with open(\"tfidf_veczr.pkl\",\"wb\") as file:\n",
    "    pickle.dump(vectorizer,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifierNB = MultinomialNB()\n",
    "classifierNB.fit(trainX,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94699999999999995"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "testX = vectorizer.transform(test_data)\n",
    "classifierNB.score(testX,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model?\n",
    "pickle.dump(classifierNB,open(\"NB_clf.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier DecisionTree\n",
    "from sklearn import tree\n",
    "classifierTree = tree.DecisionTreeClassifier()\n",
    "classifierTree.fit(trainX,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "testX = vectorizer.transform(test_data)\n",
    "classifierTree.score(testX,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save model?\n",
    "pickle.dump(classifierTree,open(\"DT_clf.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-344a023dffcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#visualize?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifierTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "#visualize?\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(classifierTree, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier log reg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifierLog = LogisticRegression()\n",
    "classifierLog.fit(trainX,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "testX = vectorizer.transform(test_data)\n",
    "classifierLog.score(testX,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save model?\n",
    "pickle.dump(classifierLog,open(\"Log_clf.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier svm\n",
    "from sklearn import svm\n",
    "classifierSVM = svm.LinearSVC()\n",
    "classifierSVM.fit(trainX,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "testX = vectorizer.transform(test_data)\n",
    "classifierSVM.score(testX,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save model?\n",
    "pickle.dump(classifierSVM,open(\"SVM_clf.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
